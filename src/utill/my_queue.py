from loguru import logger
from typing import Callable
import concurrent.futures
import queue

class StreamingQ:
    def __init__(self, producer_func: Callable, producer_args: tuple, consumer_func: Callable, max_queue_size: int = 0):
        self.producer_func = producer_func
        self.producer_args = producer_args
        self.consumer_func = consumer_func
        
        # Use maxsize for backpressure control (0 = unlimited)
        self.q = queue.Queue(maxsize=max_queue_size)

    def execute(self):
        """
        Execute producer and consumer with true streaming using generators.
        Yields consumer results as they become available.
        """
        def producer():
            try:
                for item in self.producer_func(*self.producer_args):
                    self.q.put(item)
                    logger.debug(f'ðŸŒ¾ Produced {item}')
            except Exception as e:
                logger.error(f'Producer error: {e}')
                self.q.put(('ERROR', e))
            finally:
                # Signal end of production
                self.q.put(None)
                logger.debug('ðŸŒ¾ Producer finished')

        def consumer():
            while True:
                item = self.q.get()
                
                if item is None:
                    # End of stream signal
                    self.q.task_done()
                    break
                
                if isinstance(item, tuple) and item[0] == 'ERROR':
                    # Propagate producer error
                    self.q.task_done()
                    raise item[1]
                
                try:
                    # Unpack item if it's a tuple, otherwise pass as single arg
                    if isinstance(item, tuple):
                        result = self.consumer_func(*item)
                    else:
                        result = self.consumer_func(item)
                    
                    self.q.task_done()
                    logger.debug(f'ðŸ”¥ Consumed {item} -> {result}')
                    yield result
                
                except Exception as e:
                    self.q.task_done()
                    logger.error(f'Consumer error processing {item}: {e}')
                    raise

        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            # Start producer in background
            future_producer = executor.submit(producer)
            
            try:
                # Yield results as they become available
                for result in consumer():
                    yield result
                
                # Wait for producer to complete
                future_producer.result()
                
            except Exception as e:
                # Cancel producer if consumer fails
                future_producer.cancel()
                raise



class ThreadingQ:
    def __init__(self) -> None:
        self.q = queue.Queue()

        self.producer_func = None
        self.producer_args = None
        self.consumer_func = None

    def add_producer(self, func, *args):
        self.producer_func = func
        self.producer_args = args or []
        return self

    def add_consumer(self, func):
        self.consumer_func = func
        # The consume args is based on producer output
        return self

    def execute(self):
        if not all([self.producer_func is not None, self.producer_args is not None, self.consumer_func is not None]):
            raise Exception('Producer and Consumer functions must be defined!')

        def producer():
            results = []

            for item in self.producer_func(*self.producer_args):
                self.q.put(item)
                results.append(item)
                logger.debug(f'ðŸŒ¾ Produced {item}')

            self.q.put(None)
            return results

        def consumer():
            results = []

            while True:
                item = self.q.get()
                if item is None:
                    break

                result = self.consumer_func(*item)
                results.append(result)

                self.q.task_done()
                logger.debug(f'ðŸ”¥ Consumed {item}')

            return results

        with concurrent.futures.ThreadPoolExecutor() as executor:
            # Schedule the producer and consumer
            self.future_producer = executor.submit(producer)
            self.future_consumer = executor.submit(consumer)

            producer_result = self.future_producer.result()
            logger.debug('âœ… Producer done')
            consumer_result = self.future_consumer.result()
            logger.debug('âœ… Consumer done')

        return producer_result, consumer_result
